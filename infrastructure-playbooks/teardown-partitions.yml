- name: tear down existing OSD filesystems and Logical Volumes
  hosts:
  - osds

  tasks:
  - name: Include vars of partition_vars.yaml
    include_vars:
      file: partition_vars.yaml

  # need to check if lvm2 is installed
  - name: install lvm2
    package:
      name: lvm2
      state: present

  - name: calculate partition and LV sizes
    local_action: "shell python calcPartitions.py {{nvmedev_size}} {{numJOURNALs}} {{nvme_FSjournal_size}}"
    register: part_sizes

  - name: define nvme_BI_size
    set_fact:
      nvme_BI_size={{part_sizes.stdout_lines[0]}}

  - name: identify partitions to use for nvme devices (NVMEdev1)
    shell: "for n in `seq 1 {{numNVMeParts}}` ; do echo {{nvmedev1}}$n ; done"
    register: nvmedev1_parts

  - name: check that lists are the same length (NVMEdev1)
    shell: "echo {{nvmedev1_parts.stdout_lines}} {{datadev1_hdds}}"
    failed_when: "{{nvmedev1_parts.stdout_lines|length}} != {{numNVMeParts}}"

# BEGIN TEARDOWN
  - name: find any existing OSD filesystems
    shell: "grep /var/lib/ceph/osd /proc/mounts | awk '{print $2}'"
    register: old_osd_filesystems

  - name: tear down any existing OSD filesystems
    shell: "umount -v {{item}}"
    with_items: "{{old_osd_filesystems.stdout_lines}}"

  - name: kill all LVM commands that may have been hung
    shell: "killall -q lvcreate pvcreate vgcreate lvconvert || echo -n"
    failed_when: false

## LogVols
  - name: identify any existing ceph LVs
    shell: "lvscan | grep lv-ceph | awk '/ACTIVE/ { print $2 }' | tr -d \"'\""
    register: old_ceph_lvs

  - name: tear down any existing LVM logical volumes
    shell: "echo y | lvremove -f {{item}}"
    with_items: "{{old_ceph_lvs.stdout_lines}}"

## Volume Groups
  - name: identify any existing ceph VGs
    shell: "vgscan | grep vg-ceph | awk '/Found/ { print $4 }' | tr '\"' ' '"
    register: old_ceph_vgs

  - name: tear down any existing VG
    shell: "vgremove -f {{item}}"
    with_items: "{{old_ceph_vgs.stdout_lines}}"

  - name: tear down any existing hdd PVs
    shell: "pvdisplay {{item}}1 ; if [ $? == 0 ] ; then  pvremove --force --yes {{item}}1 ; fi "
    with_items: 
      - "{{datadev1_hdds}}"
  - name: tear down any existing nvme PVs
    shell: "pvdisplay {{item}} ; if [ $? == 0 ] ; then  pvremove --force --yes {{item}} ; fi "
    with_items: 
      - "{{nvmedev1_parts.stdout_lines}}"

  - name: wait a sec
    shell: sleep 1

  - name: tear down datadev partitions
    shell: "if [ -e {{item}}1 ] ; then parted -s {{item}} rm 1 ; fi"
    with_items: 
      - "{{datadev1_hdds}}"
    
  - name: tear down nvme partitions  (NVME1)
    shell: "if [ -e {{item}} ] ; then parted -s {{nvmedev1}} rm `echo {{item}} | sed s,{{nvmedev1}},,` ; fi"
    with_items:
      - "{{nvmedev1_parts.stdout_lines}}"

  - block:
      - name: end play if TEARDOWNonly is defined
        debug:
          msg: "ending play. TEARDOWNonly is defined"

      - meta: end_play
    when: TEARDOWNonly is defined

